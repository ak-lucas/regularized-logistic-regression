{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística com Descida de Gradiente Regularizada\n",
    "\n",
    "Este notebook foi criado para facilitar a realização dos experimentos do trabalho. Caso funcione bem, podemos adotar esta ferramenta também em trabalhos futuros.\n",
    "\n",
    "**Conteúdo do notebook: **\n",
    "\n",
    "- classe com a implementação da regressão logística com descida de gradiente regularizada;\n",
    "- main com exemplo de utilização da classe;\n",
    "- código para gerar os resultados e realizar os experimentos;\n",
    "- avaliação dos resultados;\n",
    "\n",
    "**Requisitos para executar este notebook: **\n",
    "- ter os arquivos do repositório deste notebook na mesma pasta;\n",
    "- ter numpy instalado (recomendável instalar toda pilha scipy);\n",
    "- ter sklearn instalado caso queira comparar os resultados;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe da regressão logística com descida de gradiente regularizada:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Hyperparameters: \n",
    "#\t-Lambda: fator de regularização\n",
    "#\t-learning_rate: taxa de aprendizado\n",
    "#\t-epochs: número de iterações\n",
    "\n",
    "class RegularizedLogisticRegression():\n",
    "\tdef __init__(self):\n",
    "\t\tself.theta_n = []\n",
    "\t\tself.theta_0 = 0.\n",
    "\t\tself.loss = []\n",
    "\n",
    "\tdef sigmoid(self, x):\n",
    "\t\treturn (1/(1+np.exp(-x)))\n",
    "\n",
    "\t#inicializa os pesos aleatoriamente com amostras da distribuição normal\n",
    "\tdef init_weights(self, dim):\n",
    "\t\treturn np.random.randn(dim).reshape(dim,1)\n",
    "\t\t#return np.ones(dim).reshape(dim,1)\n",
    "\n",
    "\t#função de custo: cross-entropy\n",
    "\tdef loss_function(self, Y, sigmoid_z, Lambda, m):\n",
    "        # VERIFICAR SE A PARTE DA REGULARIZAÇÃO ESTÁ CERTA\n",
    "\t\tloss = -np.sum(np.multiply(Y,np.log(sigmoid_z)) + np.multiply(1-Y,np.log(1-sigmoid_z)))/m + np.multiply(np.sum(np.power(self.theta_n,2)), Lambda)/m\n",
    "\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef prints(self, epoch):\n",
    "\t\tprint(\"--epoca %s: \" % epoch)\n",
    "\t\tprint(\"loss: \", self.loss[epoch])\n",
    "\t\tprint(\"theta: \", self.theta_0.reshape(theta[0].shape[0]), self.theta_n.reshape(theta[1].shape[0]))\n",
    "\n",
    "\tdef gradient_descent(self, epochs, X, Y, Lambda, learning_rate, m, print_results):\n",
    "\t\tfor i in range(epochs):\n",
    "\t\t\t#calcula Z\n",
    "\t\t\tZ = np.dot(self.theta_n.T, X) + self.theta_0\n",
    "\n",
    "\t\t\t#calcula gradientes\n",
    "\t\t\tsigmoid_z = self.sigmoid(Z)\t#função de ativação\n",
    "\n",
    "\t\t\tgZ = sigmoid_z - Y\n",
    "\t\t\t\n",
    "\t\t\tgTheta_n = np.dot(X, gZ.T)/m\n",
    "\t\t\tgTheta_0 = np.sum(gZ)/m\n",
    "\n",
    "\t\t\t#calcula função de custo\n",
    "\t\t\tloss = self.loss_function(Y, sigmoid_z, Lambda, m)\n",
    "\t\t\tself.loss.append(loss)\n",
    "\n",
    "\t\t\t#atualiza pesos\n",
    "\t\t\tself.theta_0 -= learning_rate*gTheta_0\n",
    "\t\t\tself.theta_n = self.theta_n*(1-(learning_rate*Lambda/m)) - learning_rate*gTheta_n\n",
    "\n",
    "\t\t\tif print_results:\n",
    "\t\t\t\tself.prints(i)\n",
    "\n",
    "\t\t#calcula função de custo final\n",
    "\t\tZ = np.dot(self.theta_n.T, X) + self.theta_0\n",
    "\t\tsigmoid_z = self.sigmoid(Z)\t#função de ativação\n",
    "\t\tloss = self.loss_function(Y, sigmoid_z, Lambda, m)\n",
    "\n",
    "\t\tself.loss.append(loss)\n",
    "\n",
    "\tdef fit(self, X, Y, epochs=3, learning_rate=0.01, Lambda=0.001, print_results=False):\n",
    "\t\t#dimensão dos dados\n",
    "\t\tm = X.shape[0]\n",
    "\t\tn = X.shape[1]\n",
    "\n",
    "\t\t#inicializa os pesos aleatoriamente\n",
    "\t\tself.theta_n = self.init_weights(n)\n",
    "\t\tself.theta_0 = self.init_weights(1)\n",
    "\t\t\n",
    "\t\tX = X.T\n",
    "\t\tY = Y.reshape(1,m)\n",
    "\n",
    "\t\t#verifica as dimensões\n",
    "\t\t#assert(self.theta_n.shape[0] == X.shape[0])\n",
    "\t\t\n",
    "\t\tself.gradient_descent(epochs, X, Y, Lambda, learning_rate, m, print_results)\n",
    "\n",
    "\t\treturn self\n",
    "\n",
    "\tdef accuracy_score(self, X, Y):\n",
    "\t\tm = X.shape[0]\n",
    "\t\tY_pred = self.predict(X)\n",
    "\t\t#número de exemplos menos o número de erros dividido pelo número de exemplos\n",
    "\t\taccuracy =  float(m - np.sum(np.logical_xor(Y_pred, Y)))/m\n",
    "\n",
    "\t\treturn accuracy\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\tX = X.T\n",
    "\n",
    "\t\t#verifica as dimensões antes de fazer o produto interno\n",
    "\t\t#assert(self.theta_n.shape[0] == X.shape[0])\n",
    "\n",
    "\t\tZ = np.dot(self.theta_n.T, X) + self.theta_0\n",
    "\t\tsigmoid_z = self.sigmoid(Z)\t#função de ativação\n",
    "\n",
    "\t\t#Z.shape == (1,m)\n",
    "\t\t#sigmoid_z.shape = (1,m) -> todas as predições estão neste array\n",
    "\n",
    "\t\t#verifica se cada predição é maior ou igual a 0.5 e atribui classe 0 ou 1\n",
    "\t\tY_predict = np.greater_equal(sigmoid_z, 0.5)\n",
    "\n",
    "\t\treturn Y_predict.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exemplo de uso**\n",
    "\n",
    "Neste exemplo é utilizada uma versão modificada do dataset iris do repositório UCI. Neste dataset uma classe foi excluída para que o dataset fosse transformado para ser utlizado em um problema de classificação binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 100.0%\n",
      "test accuracy: 100.0%\n",
      "final loss: 0.0542353052139\n"
     ]
    }
   ],
   "source": [
    "#aqui no notebook não precisa importar, mas pra executar localmente com o interpretador precisa\n",
    "#from regressao_logistica_regularizado import RegularizedLogisticRegression\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "#PREPARAÇÃO DO DATASET\n",
    "X = []\n",
    "Y = []\n",
    "with open('iris_mod.csv', 'r') as f:\n",
    "\treader = csv.reader(f)\n",
    "\tfor r in reader:\n",
    "\t\tx = r[:-1]\n",
    "\t\tX.append([float(a) for a in x])\n",
    "\t\tY.append(int(r[-1]))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "\n",
    "TRAIN_SIZE = int(.8 * X.shape[0])\n",
    "\n",
    "X_train = X[:TRAIN_SIZE]\n",
    "Y_train = Y[:TRAIN_SIZE]\n",
    "\n",
    "X_test = X[TRAIN_SIZE:]\n",
    "Y_test = Y[TRAIN_SIZE:]\n",
    "\n",
    "#REGRESSÃO LOGÍSTICA\n",
    "LR = RegularizedLogisticRegression()\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "LR.fit(X_train,Y_train, epochs=epochs, learning_rate=0.08, Lambda=0.1, print_results=False)\n",
    "print(\"train accuracy: \" + str(LR.accuracy_score(X_train,Y_train)*100.0) + \"%\")\n",
    "\n",
    "Y_predict = LR.predict(X_test)\n",
    "\n",
    "print('test accuracy: ' + str(LR.accuracy_score(X_test,Y_test)*100.0) + \"%\")\n",
    "#print accuracy_score(Y_test,Y_predict)\t#sklearn accuracy\n",
    "\n",
    "print('final loss: ' + str(LR.loss[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss x Iteração**\n",
    "\n",
    "Abaixo está o código para plotar o gráfico da função de custo ao longo de cada iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcXXV9//HXO3vIJJAQHAIEApIAYREYpCDLI6FqgSrU\nigq1tIg2PvxJq4DW5VfRYi3UBZfiUir+LHWJCi5RqVA1QbCAJEhYEkLJgkkISxKWTAiQZD6/P77n\nTm4md2buTO6Zc5f38/E4j3vuOeee+/nOhfvO/X7PoojAzMwMYFjRBZiZWf1wKJiZWTeHgpmZdXMo\nmJlZN4eCmZl1cyiYmVk3h4JZA5P0dkm3DvK1D0maVeOSrMHJ5ylYniStAtqB7UAn8AvgkojoLLKu\nImR/i3dFxC8LeO9vAmsi4h+G+r2tsfiXgg2FN0ZEG3AscBzwkTzeRNLwPPZr1kocCjZkIuIJ4BZS\nOAAgabSkz0r6g6QnJX1N0tiy9X8vaZ2kxyW9S1JIOjRb901JX5V0s6TNwOy+9idpsqSfSXpW0kZJ\nt0salq37kKS1kjZJWibpj7PlJ0q6M3vNOknXShpVVt9rJN0j6bns8TWD+dtI+htJj2Z1zZO0X9m6\n12c1PSfpK5Juk/SubN1Fku7I5iXp85KekvS8pAckHSVpDvB24O8ldUr6abb9KkmvzeaHS/qopOXZ\n32CRpKnZui9KWp3tc5Gk0wbTRmsMDgUbMpIOAM4CHi1bfDUwgxQUhwL7A1dk258JXAa8Nls3q8Ju\n/wL4FDAeuKOv/QGXA2uAfUhdWh8FQtJhwCXAqyNiPPAnwKrsNduBS4HJwMnAHwP/J6tvEvBz4EvA\n3sA1wM8l7T3Av8sZwFXAW4EpwGPA3GzdZOBG0q+rvYFlQG/B83rg9Kz9e2b72xAR1wHfBj4dEW0R\n8cYKr70MuAA4G5gAXAy8kK27h/T3nAR8B/iBpDEDaaM1kIjw5Cm3ifTl2glsAgL4FbBXtk7AZuCV\nZdufDKzM5r8BXFW27tBsH4dmz78J3FC2vr/9XQn8pPT6Hvt9ihQ+I/tpz/uBH2XzFwK/67H+TuCi\nPv4Wr62w/HrSF3bpeRuwFZgG/BVwZ482riaNTQBcBNyRzZ8BPAKcBAzr8R7fBP6pt3pIYXNulZ/p\nM8Criv5vy1M+k38p2FD4s0j/Ap8FHE76Vzekf7HvASzKumeeJQ1E75Ot34/0BVhSPl9pWX/7+wzp\nV8qtklZI+jBARDxK+rL/BPCUpLml7htJM7IupyckPQ/8c1n9+5H+VV/uMdKvk4HYaT+RBuE3ZPvZ\n6W8Q6Vt5TaWdRMSvgWuBL2ftuE7ShCprmAosr7RC0gckLc26r54l/QqZXGlba3wOBRsyEXEb6V+s\nn80WrQe2AEdGxF7ZtGekQWmAdcABZbuYWmm3ZfN97i8iNkXE5RFxCHAOcFlp7CAivhMRpwIHZfv8\nl2yfXwUeBqZHxARSl5OydY9n25c7EFhb5Z+kZKf9SBpH6ipaS4+/gSSx899kJxHxpYjoAGaSupE+\nWFrVTw2rgVf2XJiNH/w9qStqYkTsBTzHjr+BNRmHgg21LwCvk/SqiOgC/h34vKRXAEjaX9KfZNt+\nH3iHpCMk7QF8rK8d97c/SW+QdGj2xfocabygS9Jhks6QNBp4kRQsXdluxwPPA52SDgfeU/aWNwMz\nJP2FpBGS3kb6Mv5ZH2WOlDSmbBoBfDdr57FZDf8M3B0Rq0hjFkdL+rNs2/cC+1basaRXS/ojSSNJ\n3WgvlrXjSeCQPur6OvBJSdOzAetjsrGR8cA24GlghKQrSGMO1qQcCjakIuJp4AZ2DP5+iNSlc1fW\nPfNL4LBs2/8iDeLOL22TvealPt6i1/0B07PnnaS+/69ExHxgNGmAej3wBPAKdhw2+wHSYPYmUuB8\nr6wtG4A3kAawN5D+Rf2GiFjfR303k0KnNH0i0nkLHwNuIv0yeCVwfvYe64G3AJ/O3mMmsLCXv8GE\nrMZnSN1RG0hdZpDGLWZm3Wo/rvDaa0ghfCspBK8HxpKOFvsFaaziMVLQVOrGsybhk9esYUg6AngQ\nGB0R24qupwhKh9CuAd6eBZpZTfmXgtU1SW9SOvdgIqmf/6etFgiS/kTSXlnXUmlM465+XmY2KA4F\nq3fvJh0uupw0BvCevjdvSieT2r8eeCPpaK4txZZkzcrdR2Zm1s2/FMzMrNuIogsYqMmTJ8e0adMG\n9drNmzczbty42hZUELelPjVLW5qlHeC2lCxatGh9ROzT33YNFwrTpk1j4cKFg3rtggULmDVrVm0L\nKojbUp+apS3N0g5wW0ok9Tz7viJ3H5mZWTeHgpmZdcstFCRNlTRf0hKl2/69r8I2s7KLbN2XTVdU\n2peZmQ2NPMcUtgGXR8S9ksaTrlz53xGxpMd2t0fEG3Ksw8zMqpTbL4WIWBcR92bzm4ClDPySwmZm\nNoSGZExB0jTSvXnvrrD6ZEmLJf2XpCOHoh4zM6ss9zOaJbUBtwGfiogf9lg3AeiKiE5JZwNfjIjp\nFfYxB5gD0N7e3jF37txB1dLZ2UlbW1v/GzYAt6U+NUtbmqUd4LaUzJ49e1FEnNDvhnne1g0YSbr0\n7mVVbr8KmNzXNh0dHTEYn/tcxOGHPxc33zyol9ed+fPnF11Czbgt9adZ2hHhtpQAC6PI23FmNzK5\nHlgaEdf0ss2+2XZIOpHUnbUhj3pWr4aHH57A4sV57N3MrDnkefTRKaQbmz8g6b5s2UdJtyskIr4G\nnAe8R9I20g1Hzs8SreYOPzw9LluWx97NzJpDbqEQEXfQz31cI+Ja0o3Gc3dYdu8th4KZWe9a5ozm\nUig8/DD4auFmZpW1TCjsuy+MG7eNZ56B9X3dQdfMrIW1TChIMHXqC4C7kMzMetMyoQA7QuHhhwsu\nxMysTrVUKBx4oH8pmJn1paVCYerUdK9zh4KZWWUtFgruPjIz60tLhcIBB2xBghUr4OWXi67GzKz+\ntFQojBrVxbRpsH17CgYzM9tZS4UC7HwSm5mZ7azlQsHXQDIz613LhYKvgWRm1ruWDQV3H5mZ7arl\nQsHdR2ZmvWu5UNh3Xxg/HjZu9IXxzMx6arlQkNyFZGbWm5YLBXAXkplZb1oyFHwEkplZZS0dCu4+\nMjPbWUuGgruPzMwqa8lQOPRQui+Mt3Vr0dWYmdWPlgyFsWPhoINg2zZYvrzoaszM6kdLhgK4C8nM\nrJKWDQUfgWRmtquWDwUfgWRmtkPLhoK7j8zMdtWyoeDuIzOzXbVsKEyZAm1tsGGDL4xnZlbSsqEg\nuQvJzKynlg0FcBeSmVlPDgV8BJKZWUlLh4K7j8zMdpZbKEiaKmm+pCWSHpL0vgrbSNKXJD0q6X5J\nx+dVTyXuPjIz21mevxS2AZdHxEzgJOC9kmb22OYsYHo2zQG+mmM9u5g+PQ04L1/uC+OZmUGOoRAR\n6yLi3mx+E7AU2L/HZucCN0RyF7CXpCl51dRT+YXxVqwYqnc1M6tfQzKmIGkacBxwd49V+wOry56v\nYdfgyJW7kMzMdhiR9xtIagNuAt4fEc8Pch9zSN1LtLe3s2DBgkHV0tnZuctrx407FDiAn/98ORMm\nrK74unpUqS2Nym2pP83SDnBbBiwicpuAkcAtwGW9rP834IKy58uAKX3ts6OjIwZr/vz5uyz7ylci\nIOLiiwe920JUakujclvqT7O0I8JtKQEWRhXf23kefSTgemBpRFzTy2bzgL/KjkI6CXguItblVVMl\n7j4yM9shz+6jU4ALgQck3Zct+yhwIEBEfA24GTgbeBR4AXhHjvVU5BPYzMx2yC0UIuIOQP1sE8B7\n86qhGvvtt+PCeBs2wN57F1mNmVmxWvqMZkjnKbgLycwsaflQAHchmZmVOBTwNZDMzEocCrj7yMys\nxKGAu4/MzEocCvjCeGZmJQ4FYI894MAD04XxVq4suhozs+I4FDLuQjIzcyh08xFIZmYOhW4+AsnM\nzKHQzd1HZmYOhW7uPjIzcyh0K10Yb/36dGE8M7NW5FDISDBjRpr3rwUza1UOhTLuQjKzVudQKOMj\nkMys1TkUyvgIJDNrdQ6FMu4+MrNW51AoM316evSF8cysVTkUypQujLd1qy+MZ2atyaHQg7uQzKyV\nORR68BFIZtbKHAo9lH4pLFlSbB1mZkVwKPRw1FHp8aGHiq3DzKwIDoUejjwyPT70EHR1FVuLmdlQ\ncyj0sPfeMGUKbN4Mq1YVXY2Z2dByKFRw9NHp8cEHi63DzGyoORQqKI0rOBTMrNU4FCpwKJhZq3Io\nVOBQMLNW5VCoYObM9Pjww74Gkpm1FodCBePGwSGHpEB45JGiqzEzGzq5hYKkb0h6SlLFThhJsyQ9\nJ+m+bLoir1oGw0cgmVkryvOXwjeBM/vZ5vaIODabrsyxlgHzuIKZtaLcQiEifgNszGv/eXMomFkr\nKnpM4WRJiyX9l6QjC65lJw4FM2tFioj8di5NA34WEUdVWDcB6IqITklnA1+MiOm97GcOMAegvb29\nY+7cuYOqp7Ozk7a2tqq23bpVnHXWaXR1iZ///HbGjq2vCyENpC31zm2pP83SDnBbSmbPnr0oIk7o\nd8OIyG0CpgEPVrntKmByf9t1dHTEYM2fP39A2x95ZARE3HPPoN8yNwNtSz1zW+pPs7Qjwm0pARZG\nFd/FhXUfSdpXkrL5E0ldWRuKqqcSH4FkZq1mRF47lvRdYBYwWdIa4OPASICI+BpwHvAeSduALcD5\nWZrVDY8rmFmryS0UIuKCftZfC1yb1/vXgkPBzFpN0Ucf1bVSKDzwQLF1mJkNFYdCHw4+GMaOhccf\nh40Ne8aFmVn1HAp9GDZs59tzmpk1O4dCP3wEkpm1EodCPzzYbGatxKHQD4eCmbUSh0I/yo9Aqq+z\nKMzMas+h0I8pU2DiRHjmGVi3ruhqzMzyVVUoSHqfpAlKrpd0r6TX511cPZA82GxmraPaXwoXR8Tz\nwOuBicCFwNW5VVVnPK5gZq2i2lBQ9ng28J8R8VDZsqbnUDCzVlFtKCySdCspFG6RNB6orxsM5MiX\nuzCzVlHtBfHeCRwLrIiIFyRNAt6RX1n1pfys5q6udKazmVkzqvbr7WRgWUQ8K+kvgX8AnsuvrPoy\naRLstx9s2QIrVxZdjZlZfqoNha8CL0h6FXA5sBy4Ibeq6pCPQDKzVlBtKGzLboBzLnBtRHwZGJ9f\nWfXHg81m1gqqHVPYJOkjpENRT5M0jOwuaq3CoWBmraDaXwpvA14ina/wBHAA8JncqqpDPgLJzFpB\nVaGQBcG3gT0lvQF4MSJaakzhiCPS2c3LlsHLLxddjZlZPqq9zMVbgd8BbwHeCtwt6bw8C6s348bB\nIYfAtm3wyCNFV2Nmlo9qxxT+L/DqiHgKQNI+wC+BG/MqrB4dfTQsX57GFUrdSWZmzaTaMYVhpUDI\nbBjAa5uGB5vNrNlV+0vhF5JuAb6bPX8bcHM+JdUvh4KZNbuqQiEiPijpzcAp2aLrIuJH+ZVVn3wE\nkpk1u2p/KRARNwE35VhL3Zs+HUaOhBUrYPPmNPhsZtZM+hwXkLRJ0vMVpk2Snh+qIuvFqFFw2GFp\nfsmSYmsxM8tDn6EQEeMjYkKFaXxETBiqIuuJr4FkZs2s5Y4g2l0ebDazZuZQGCAPNptZM3MoDJB/\nKZhZM3MoDNC0aemoo3XrYMOGoqsxM6sth8IADRu28+05zcyaSW6hIOkbkp6SVLGjRcmXJD0q6X5J\nx+dVS625C8nMmlWevxS+CZzZx/qzgOnZNId0y8+G4FAws2aVWyhExG+AjX1sci5wQyR3AXtJmpJX\nPbXkI5DMrFkp3Xo5p51L04CfRcQuF5qW9DPg6oi4I3v+K+BDEbGwwrZzSL8maG9v75g7d+6g6uns\n7KStrW1Qry23YcMozjvvNbS1bWXevN8i7fYuB6xWbakHbkv9aZZ2gNtSMnv27EURcUK/G0ZEbhMw\nDXiwl3U/A04te/4r4IT+9tnR0RGDNX/+/EG/tlxXV8SkSREQsWZNTXY5YLVqSz1wW+pPs7Qjwm0p\nARZGFd/bRR59tBaYWvb8gGxZ3ZN8uQsza05FhsI84K+yo5BOAp6LiHUF1jMgHmw2s2ZU9aWzB0rS\nd4FZwGRJa4CPAyMBIuJrpJv0nA08CrwAvCOvWvLgwWYza0a5hUJEXNDP+gDem9f75+347KyKO+8s\ntg4zs1ryGc2DdPzxMH48PPIIrFlTdDVmZrXhUBikESPg9NPT/Pz5xdZiZlYrDoXdcMYZ6fHXvy62\nDjOzWnEo7IbyUMjxHEAzsyHjUNgNxxwDkybBH/4AK1cWXY2Z2e5zKOyGYcNg1qw07y4kM2sGDoXd\n5HEFM2smDoXd5HEFM2smDoXddPjhsO++8OSTsHRp0dWYme0eh8Juknb8WvD5CmbW6BwKNTB7dnr0\nuIKZNTqHQg2U/1Lo6iq2FjOz3eFQqIGDD4aDDoJnnoHFi4uuxsxs8BwKNeBxBTNrFg6FGvH5CmbW\nDBwKNVIabL7tNti6tdhazMwGy6FQI/vvDzNmQGcnLFpUdDVmZoPjUKghdyGZWaNzKNSQB5vNrNE5\nFGqodMXUO+6Al14qtBQzs0FxKNTQPvvA0UfDiy/CXXcVXY2Z2cA5FGrM4wpm1sgcCjXmcQUza2QO\nhRo7/fR0R7a77oLNm4uuxsxsYBwKNbbXXnD88ekEtt/+tuhqzMwGxqGQA48rmFmjcijkwKFgZo3K\noZCDU0+FESPS5S6ee67oaszMqudQyMG4cXDSSemGO7/5TdHVmJlVz6GQE9+i08wakUMhJx5XMLNG\n5FDIyUknwZgxcP/9sH590dWYmVUn11CQdKakZZIelfThCusvkvS0pPuy6V151jOUxoyBU05J8wsW\nFFqKmVnVcgsFScOBLwNnATOBCyTNrLDp9yLi2Gz6el71FMHjCmbWaPL8pXAi8GhErIiIl4G5wLk5\nvl/d8biCmTUaRUQ+O5bOA86MiHdlzy8E/igiLinb5iLgKuBp4BHg0ohYXWFfc4A5AO3t7R1z584d\nVE2dnZ20tbUN6rWDsW2bOOecU9iyZQQ/+MH/MHnyyzXb91C3JU9uS/1plnaA21Iye/bsRRFxQr8b\nRkQuE3Ae8PWy5xcC1/bYZm9gdDb/buDX/e23o6MjBmv+/PmDfu1gnX12BER861u13W8RbcmL21J/\nmqUdEW5LCbAwqvjuzrP7aC0wtez5Admy8kDaEBGle5R9HejIsZ5CuAvJzBpJnqFwDzBd0sGSRgHn\nA/PKN5A0pezpOcDSHOspRCkUfvITePbZYmsxM+tPbqEQEduAS4BbSF/234+IhyRdKemcbLO/k/SQ\npMXA3wEX5VVPUY49Fk47DTZsgE9+suhqzMz6lut5ChFxc0TMiIhXRsSnsmVXRMS8bP4jEXFkRLwq\nImZHxMN51lMECb74xfT4pS/BsmVFV2Rm1juf0TwEjjsO3vlO2LYNLrus6GrMzHrnUBgi//RPMGEC\n3HxzmszM6pFDYYi0t8MVV6T5yy6Dl2t3yoKZWc04FIbQ3/4tTJ+exhW+/OWiqzEz25VDYQiNGgWf\n/3ya/8d/hKefLrYeM7OeHApD7Oyz4cwz0206P/axoqsxM9uZQ2GISXDNNTB8OFx3Hdx3X9EVmZnt\n4FAowBFHwCWXQAS8//3p0cysHjgUCvLxj8Pee8Ntt8FNNxVdjZlZ4lAoyMSJ6dwFgA98ALZsKbYe\nMzNwKBTqb/4GjjkGHnsMPve5oqsxM3MoFGr4cPjCF9L8VVfB2rV9b29mljeHQsFmz4Y//3N44QX4\n8IeLrsbMWp1DoQ585jMwejR861tw551FV2NmrcyhUAcOOQQuvzzNv/vd8Ic/FFuPmbUuh0Kd+MhH\nYNo0eOABOPro9KvB5y+Y2VBzKNSJtja4+2445xx4/nm48EJ429tg48aiKzOzVuJQqCOveAX8+Mdw\n/fUpJH7wAzjqKLjllqIrM7NW4VCoMxJcfDEsXgynnALr1qUL6F1ySTpCycwsTw6FOnXIIekSGFdd\nBSNHpvsvHHcc3HNP0ZWZWTNzKNSx4cPTuQt33w0zZ8Ijj8DJJ8OVV8L27Sq6PDNrQg6FBnDccbBo\nEVx6KWzfni6mN2dOB1/4AqxeXXR1ZtZMHAoNYsyYdB+GX/0Kpk6FFSvauPRSOPBAOOkk+OxnYeXK\noqs0s0bnUGgwZ5wBS5fCxz62hDe/GcaOTd1LH/xgGoc44QS4+mr43/8tulIza0QOhQY0bhycccZT\n3Hhjus/zjTfC+eenw1gXLUonws2YAccem7qafvrTdCVWnwxnZv0ZUXQBtnvGjYM3vzlNW7bArbem\nkJg3Lx3Wunjxjm0nTEiX6j766PR4zDHpPIgJE4qr38zqi0OhiYwdC+eem6aXXoJf/jKNQTzwQAqH\np5+GO+5IU7mDD07hcNBBcMABsP/+6bE0P3ZsMe0xs6HnUGhSo0fDn/5pmkqefBLuv3/nacmSNEDd\n1yD1pEk7h8TkyWnZxInpsTSVno8dm07CM7PG41BoIe3t8LrXpalk69Z0/sOSJbBmTZrWrt0x//jj\n6fpLGzemEKnG6NEpICZMSOMcbW2pm6s0Xz6NGwerV09h9ep0hNWYMSlUSvPl0+jRMGpUOplv1Kh0\nHofDx6y2HAotbuRIOPLINFXS1ZW6nUphsXbtjpAoTc88s/Pzl16CJ55IU3UOG1Tt0s4hUT4/YsSu\n08iRuy4bNiyFSzXTsGE7ti/N93z+2GMH8dvfptpKyyrNS33PV3q+u1Ppb1bN88WLJ7J1667L+5sf\n6GNfyyq9ZiD7L82vXLkHr3hF//sZbBuq2V+tXrNpU/5f2Q4F69OwYekXRns7dHRU95otW1I4dHbu\nOm3evOuyFSseZ+LE/XjxxfTaF1/cddqyJYXN1q3w8stp6upKy156Kd+/wcAcXHQBNfKqoguooROL\nLqBmjjjiGN74xnzfw6FgNTd2bBp7qNaCBY8wa9Z+A36f7dt3Dony+e3bYdu2NG3dumO+fNq6NW3X\n1ZUe+5q6unZsV5rv+Xz7dli1ahVTp06jqysdAlxaVz5fel6ayp/3Nr+7E1T/HGDjxo3stdekXZb3\nNV/tYzXrKq0fyPuUz2/evJk99hhXs31X89qBrB/Ia9ratpG3XENB0pnAF4HhwNcj4uoe60cDNwAd\nwAbgbRGxKs+arHmUunXGjCm6kh0WLFjFrFnTii5jty1YcD+zZs0quoyaWLDgniZqy/3ArFzfI7eT\n1yQNB74MnAXMBC6QNLPHZu8EnomIQ4HPA/+SVz1mZta/PM9oPhF4NCJWRMTLwFzg3B7bnAv8RzZ/\nI/DHko8nMTMriiKnax9IOg84MyLelT2/EPijiLikbJsHs23WZM+XZ9us77GvOcAcgPb29o65c+cO\nqqbOzk7a2toG9dp647bUp2ZpS7O0A9yWktmzZy+KiBP6264hBpoj4jrgOoATTjghBts/uGDBgibq\nW3Rb6lGztKVZ2gFuy0Dl2X20Fpha9vyAbFnFbSSNAPYkDTibmVkB8gyFe4Dpkg6WNAo4H5jXY5t5\nwF9n8+cBv468+rPMzKxfuXUfRcQ2SZcAt5AOSf1GRDwk6UpgYUTMA64H/lPSo8BGUnCYmVlBch1T\niIibgZt7LLuibP5F4C151mBmZtXL7eijvEh6GnhskC+fDKzvd6vG4LbUp2ZpS7O0A9yWkoMiYp/+\nNmq4UNgdkhZWc0hWI3Bb6lOztKVZ2gFuy0D5dpxmZtbNoWBmZt1aLRSuK7qAGnJb6lOztKVZ2gFu\ny4C01JiCmZn1rdV+KZiZWR8cCmZm1q1lQkHSmZKWSXpU0oeLrmd3SFol6QFJ90laWHQ9AyHpG5Ke\nyq6QW1o2SdJ/S/rf7HFikTVWo5d2fELS2uxzuU/S2UXWWC1JUyXNl7RE0kOS3pctb6jPpY92NNzn\nImmMpN9JWpy15R+z5QdLujv7Hvtedgmh2r53K4wpZDf8eQR4HbCGdF2mCyJiSaGFDZKkVcAJPS8x\n3ggknQ50AjdExFHZsk8DGyPi6iywJ0bEh4qssz+9tOMTQGdEfLbI2gZK0hRgSkTcK2k8sAj4M+Ai\nGuhz6aMdb6XBPpfsvjLjIqJT0kjgDuB9wGXADyNirqSvAYsj4qu1fO9W+aVQzQ1/bAhExG9I17kq\nV36zpf8g/Y9c13ppR0OKiHURcW82vwlYCuxPg30ufbSj4UTSmT0dmU0BnEG6IRnk9Jm0SijsD6wu\ne76GBv2PJRPArZIWZTcganTtEbEum38CaC+ymN10iaT7s+6luu5uqUTSNOA44G4a+HPp0Q5owM9F\n0nBJ9wFPAf8NLAeejYht2Sa5fI+1Sig0m1Mj4njS/a/fm3VlNIXs0umN2qf5VeCVwLHAOuBzxZYz\nMJLagJuA90fE8+XrGulzqdCOhvxcImJ7RBxLuhfNicDhQ/G+rRIK1dzwp2FExNrs8SngR6T/YBrZ\nk1l/cKlf+KmC6xmUiHgy+x+5C/h3GuhzyfqtbwK+HRE/zBY33OdSqR2N/LkARMSzwHzgZGCv7IZk\nkNP3WKuEQjU3/GkIksZlg2hIGge8Hniw71fVvfKbLf018JMCaxm00hdo5k00yOeSDWpeDyyNiGvK\nVjXU59JbOxrxc5G0j6S9svmxpINklpLC4bxss1w+k5Y4+gggOwztC+y44c+nCi5pUCQdQvp1AOl+\nGN9ppLZI+i4wi3QJ4CeBjwM/Br4PHEi6LPpbI6KuB3F7accsUhdFAKuAd5f1ydctSacCtwMPAF3Z\n4o+S+uMb5nPpox0X0GCfi6RjSAPJw0n/eP9+RFyZ/f8/F5gE/B74y4h4qabv3SqhYGZm/WuV7iMz\nM6uCQ8HMzLo5FMzMrJtDwczMujkUzMysm0PBWpqk/8kep0n6i6LrMSuaQ8FaWkS8JpudBgwoFMrO\nLDVrGg4Fa2mSSleivBo4Lbve/qXZxcg+I+me7EJq7862nyXpdknzgCXZsh9nFyd8qPwChUr38Lg3\nuyb+r7JlJ0q6U9LvJf2PpMOy5WMk/T+l+2T8XtLsIf1DmGX8Lx2z5MPAByLiDQDZl/tzEfFqSaOB\n30q6NdvkdxM0AAABdklEQVT2eOCoiFiZPb84IjZmlyO4R9JNpH9w/TtwekSslDQp2/Zh4LSI2Cbp\ntcA/A28G3ku67tzRkg4nXQV3RkS8OARtN+vmUDCr7PXAMZJK15nZE5gOvAz8riwQAP5O0puy+anZ\ndvsAvyltV3Z5iD2B/5A0nXTZhZHZ8lOBf822fVjSY8AM4P48GmfWG4eCWWUC/jYibtlpoTQL2Nzj\n+WuBkyPiBUkLgDF97PeTwPyIeFN2zf8FtSzabHd5TMEs2QSML3t+C/Ce7FLMSJqRXZW2pz2BZ7JA\nOBw4KVt+F3C6pIOz108q2750ueOLyvZzO/D20nuRLkK3bHcbZTZQDgWz5H5gezYofCnwddJA8r2S\nHgT+jcq/rH8BjJC0lDRYfRdARDwNzAF+KGkx8L1s+08DV0n6fY/9fQUYJumBbNuLan31S7Nq+Cqp\nZmbWzb8UzMysm0PBzMy6ORTMzKybQ8HMzLo5FMzMrJtDwczMujkUzMys2/8HK7EAxyKHda8AAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb32e8acd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#só precisa na primeira execução\n",
    "\n",
    "#gera lista com os números das iterações\n",
    "#epochs = range(epochs)\n",
    "#epochs.append(epochs[-1] + 1)\n",
    "\n",
    "#\n",
    "\n",
    "plt.plot(epochs, LR.loss, color='blue', linewidth=2)\n",
    "#plt.axis([0,4,.092,.098])\n",
    "#plt.xticks([0,1,2,3,4])\n",
    "plt.xlabel('iteracao')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Regressao Logistica')\n",
    "plt.grid(True)\n",
    "#plt.text(.14,.55, r'$\\alpha = 0.01$')\n",
    "#aux = 'Iteracao ' + str(i+1)\n",
    "#legends.append(mpatches.Patch(color=colors[i], label=aux))\n",
    "#plt.legend(handles=legends[:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
